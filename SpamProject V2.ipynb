{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               mail\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "url = \"SMSSpamCollection.txt\"\n",
    "df = pd.read_csv(url, sep='\\t', header=None )\n",
    "df.rename(columns={0:'type',1:'mail'}, inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mail</th>\n",
       "      <th>minuscule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl. its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               mail  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham               Will ü b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                              minuscule  \n",
       "0     go until jurong point, crazy.. available only ...  \n",
       "1                         ok lar... joking wif u oni...  \n",
       "2     free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3     u dun say so early hor... u c already then say...  \n",
       "4     nah i don't think he goes to usf, he lives aro...  \n",
       "...                                                 ...  \n",
       "5567  this is the 2nd time we have tried 2 contact u...  \n",
       "5568               will ü b going to esplanade fr home?  \n",
       "5569  pity, * was in mood for that. so...any other s...  \n",
       "5570  the guy did some bitching but i acted like i'd...  \n",
       "5571                         rofl. its true to its name  \n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['minuscule']=df['mail'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RED94\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mail</th>\n",
       "      <th>minuscule</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>will ü b going to esplanade fr home?</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl. its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               mail  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham               Will ü b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                              minuscule  \\\n",
       "0     go until jurong point, crazy.. available only ...   \n",
       "1                         ok lar... joking wif u oni...   \n",
       "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3     u dun say so early hor... u c already then say...   \n",
       "4     nah i don't think he goes to usf, he lives aro...   \n",
       "...                                                 ...   \n",
       "5567  this is the 2nd time we have tried 2 contact u...   \n",
       "5568               will ü b going to esplanade fr home?   \n",
       "5569  pity, * was in mood for that. so...any other s...   \n",
       "5570  the guy did some bitching but i acted like i'd...   \n",
       "5571                         rofl. its true to its name   \n",
       "\n",
       "                                                  token  \n",
       "0     [go, until, jurong, point, crazy, available, o...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...  \n",
       "...                                                 ...  \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...  \n",
       "5568       [will, ü, b, going, to, esplanade, fr, home]  \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...  \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...  \n",
       "5571                   [rofl, its, true, to, its, name]  \n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer avec RE (regular expressions)\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "# tokenizer = RegexpTokenizer(r\"[a-zA-Z]\\w+\\'?\\w*\")\n",
    "tokenizer = RegexpTokenizer(r\"\\b\\w+\\b|\\d{2} \\d{2} \\d{2} \\d{2} \\d{2}|http\\S+\")\n",
    "\n",
    "df['token'] = df['minuscule'].apply(lambda x: tokenizer.tokenize(x))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RED94\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mail</th>\n",
       "      <th>minuscule</th>\n",
       "      <th>token</th>\n",
       "      <th>without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>will ü b going to esplanade fr home?</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl. its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               mail  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham               Will ü b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                              minuscule  \\\n",
       "0     go until jurong point, crazy.. available only ...   \n",
       "1                         ok lar... joking wif u oni...   \n",
       "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3     u dun say so early hor... u c already then say...   \n",
       "4     nah i don't think he goes to usf, he lives aro...   \n",
       "...                                                 ...   \n",
       "5567  this is the 2nd time we have tried 2 contact u...   \n",
       "5568               will ü b going to esplanade fr home?   \n",
       "5569  pity, * was in mood for that. so...any other s...   \n",
       "5570  the guy did some bitching but i acted like i'd...   \n",
       "5571                         rofl. its true to its name   \n",
       "\n",
       "                                                  token  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5568       [will, ü, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                      without_stopwords  \n",
       "0     [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3         [u, dun, say, early, hor, u, c, already, say]  \n",
       "4        [nah, think, goes, usf, lives, around, though]  \n",
       "...                                                 ...  \n",
       "5567  [2nd, time, tried, 2, contact, u, u, 750, poun...  \n",
       "5568                 [ü, b, going, esplanade, fr, home]  \n",
       "5569                          [pity, mood, suggestions]  \n",
       "5570  [guy, bitching, acted, like, interested, buyin...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "# Supprimer les stop words\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['without_stopwords']=df['token'].apply(lambda x: [word for word in x if word not in stop])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mail</th>\n",
       "      <th>minuscule</th>\n",
       "      <th>token</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>PorterStemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, think, goe, usf, live, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "      <td>[2nd, time, tri, 2, contact, u, u, 750, pound,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>will ü b going to esplanade fr home?</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, go, esplanad, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>[piti, mood, suggest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>[guy, bitch, act, like, interest, buy, someth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl. its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               mail  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham               Will ü b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                              minuscule  \\\n",
       "0     go until jurong point, crazy.. available only ...   \n",
       "1                         ok lar... joking wif u oni...   \n",
       "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3     u dun say so early hor... u c already then say...   \n",
       "4     nah i don't think he goes to usf, he lives aro...   \n",
       "...                                                 ...   \n",
       "5567  this is the 2nd time we have tried 2 contact u...   \n",
       "5568               will ü b going to esplanade fr home?   \n",
       "5569  pity, * was in mood for that. so...any other s...   \n",
       "5570  the guy did some bitching but i acted like i'd...   \n",
       "5571                         rofl. its true to its name   \n",
       "\n",
       "                                                  token  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5568       [will, ü, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                      without_stopwords  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4        [nah, think, goes, usf, lives, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, tried, 2, contact, u, u, 750, poun...   \n",
       "5568                 [ü, b, going, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitching, acted, like, interested, buyin...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                          PorterStemmer  \n",
       "0     [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                          [ok, lar, joke, wif, u, oni]  \n",
       "2     [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3         [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4          [nah, think, goe, usf, live, around, though]  \n",
       "...                                                 ...  \n",
       "5567  [2nd, time, tri, 2, contact, u, u, 750, pound,...  \n",
       "5568                     [ü, b, go, esplanad, fr, home]  \n",
       "5569                              [piti, mood, suggest]  \n",
       "5570  [guy, bitch, act, like, interest, buy, someth,...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5572 rows x 6 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "# stemmer notre list\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "df['PorterStemmer'] = df['without_stopwords'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mail</th>\n",
       "      <th>minuscule</th>\n",
       "      <th>token</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>PorterStemmer</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, think, goe, usf, live, around, though]</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "      <td>[2nd, time, tri, 2, contact, u, u, 750, pound,...</td>\n",
       "      <td>2nd time tried 2 contact u u 750 pound prize 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>will ü b going to esplanade fr home?</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, go, esplanad, fr, home]</td>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>[piti, mood, suggest]</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>[guy, bitch, act, like, interest, buy, someth,...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl. its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               mail  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham               Will ü b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                              minuscule  \\\n",
       "0     go until jurong point, crazy.. available only ...   \n",
       "1                         ok lar... joking wif u oni...   \n",
       "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3     u dun say so early hor... u c already then say...   \n",
       "4     nah i don't think he goes to usf, he lives aro...   \n",
       "...                                                 ...   \n",
       "5567  this is the 2nd time we have tried 2 contact u...   \n",
       "5568               will ü b going to esplanade fr home?   \n",
       "5569  pity, * was in mood for that. so...any other s...   \n",
       "5570  the guy did some bitching but i acted like i'd...   \n",
       "5571                         rofl. its true to its name   \n",
       "\n",
       "                                                  token  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5568       [will, ü, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                      without_stopwords  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4        [nah, think, goes, usf, lives, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, tried, 2, contact, u, u, 750, poun...   \n",
       "5568                 [ü, b, going, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitching, acted, like, interested, buyin...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                          PorterStemmer  \\\n",
       "0     [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                          [ok, lar, joke, wif, u, oni]   \n",
       "2     [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4          [nah, think, goe, usf, live, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, tri, 2, contact, u, u, 750, pound,...   \n",
       "5568                     [ü, b, go, esplanad, fr, home]   \n",
       "5569                              [piti, mood, suggest]   \n",
       "5570  [guy, bitch, act, like, interest, buy, someth,...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                                  clean  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                   u dun say early hor u c already say  \n",
       "4                nah think goes usf lives around though  \n",
       "...                                                 ...  \n",
       "5567  2nd time tried 2 contact u u 750 pound prize 2...  \n",
       "5568                        ü b going esplanade fr home  \n",
       "5569                              pity mood suggestions  \n",
       "5570  guy bitching acted like interested buying some...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5572 rows x 7 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['clean'] = df['without_stopwords'].apply(lambda x: \" \".join(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Pipeline and model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "# Score of models\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, RobustScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mail</th>\n",
       "      <th>minuscule</th>\n",
       "      <th>token</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>PorterStemmer</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, think, goe, usf, live, around, though]</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "      <td>[2nd, time, tri, 2, contact, u, u, 750, pound,...</td>\n",
       "      <td>2nd time tried 2 contact u u 750 pound prize 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>will ü b going to esplanade fr home?</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, go, esplanad, fr, home]</td>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>[piti, mood, suggest]</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>[guy, bitch, act, like, interest, buy, someth,...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl. its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               mail  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham               Will ü b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                              minuscule  \\\n",
       "0     go until jurong point, crazy.. available only ...   \n",
       "1                         ok lar... joking wif u oni...   \n",
       "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3     u dun say so early hor... u c already then say...   \n",
       "4     nah i don't think he goes to usf, he lives aro...   \n",
       "...                                                 ...   \n",
       "5567  this is the 2nd time we have tried 2 contact u...   \n",
       "5568               will ü b going to esplanade fr home?   \n",
       "5569  pity, * was in mood for that. so...any other s...   \n",
       "5570  the guy did some bitching but i acted like i'd...   \n",
       "5571                         rofl. its true to its name   \n",
       "\n",
       "                                                  token  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5568       [will, ü, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                      without_stopwords  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4        [nah, think, goes, usf, lives, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, tried, 2, contact, u, u, 750, poun...   \n",
       "5568                 [ü, b, going, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitching, acted, like, interested, buyin...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                          PorterStemmer  \\\n",
       "0     [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                          [ok, lar, joke, wif, u, oni]   \n",
       "2     [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4          [nah, think, goe, usf, live, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, tri, 2, contact, u, u, 750, pound,...   \n",
       "5568                     [ü, b, go, esplanad, fr, home]   \n",
       "5569                              [piti, mood, suggest]   \n",
       "5570  [guy, bitch, act, like, interest, buy, someth,...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                                  clean  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                   u dun say early hor u c already say  \n",
       "4                nah think goes usf lives around though  \n",
       "...                                                 ...  \n",
       "5567  2nd time tried 2 contact u u 750 pound prize 2...  \n",
       "5568                        ü b going esplanade fr home  \n",
       "5569                              pity mood suggestions  \n",
       "5570  guy bitching acted like interested buying some...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5572 rows x 7 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>mail</th>\n",
       "      <th>minuscule</th>\n",
       "      <th>token</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>PorterStemmer</th>\n",
       "      <th>clean</th>\n",
       "      <th>len</th>\n",
       "      <th>nombre_mots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, think, goe, usf, live, around, though]</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, 750, poun...</td>\n",
       "      <td>[2nd, time, tri, 2, contact, u, u, 750, pound,...</td>\n",
       "      <td>2nd time tried 2 contact u u 750 pound prize 2...</td>\n",
       "      <td>160</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>will ü b going to esplanade fr home?</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, go, esplanad, fr, home]</td>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity, * was in mood for that. so...any other s...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>[piti, mood, suggest]</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>the guy did some bitching but i acted like i'd...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>[guy, bitch, act, like, interest, buy, someth,...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "      <td>125</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl. its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>rofl true name</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               mail  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham               Will ü b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                              minuscule  \\\n",
       "0     go until jurong point, crazy.. available only ...   \n",
       "1                         ok lar... joking wif u oni...   \n",
       "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3     u dun say so early hor... u c already then say...   \n",
       "4     nah i don't think he goes to usf, he lives aro...   \n",
       "...                                                 ...   \n",
       "5567  this is the 2nd time we have tried 2 contact u...   \n",
       "5568               will ü b going to esplanade fr home?   \n",
       "5569  pity, * was in mood for that. so...any other s...   \n",
       "5570  the guy did some bitching but i acted like i'd...   \n",
       "5571                         rofl. its true to its name   \n",
       "\n",
       "                                                  token  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5568       [will, ü, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                      without_stopwords  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4        [nah, think, goes, usf, lives, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, tried, 2, contact, u, u, 750, poun...   \n",
       "5568                 [ü, b, going, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitching, acted, like, interested, buyin...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                          PorterStemmer  \\\n",
       "0     [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                          [ok, lar, joke, wif, u, oni]   \n",
       "2     [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4          [nah, think, goe, usf, live, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, tri, 2, contact, u, u, 750, pound,...   \n",
       "5568                     [ü, b, go, esplanad, fr, home]   \n",
       "5569                              [piti, mood, suggest]   \n",
       "5570  [guy, bitch, act, like, interest, buy, someth,...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                                  clean  len  nombre_mots  \n",
       "0     go jurong point crazy available bugis n great ...  111           20  \n",
       "1                               ok lar joking wif u oni   29            6  \n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...  155           28  \n",
       "3                   u dun say early hor u c already say   49           11  \n",
       "4                nah think goes usf lives around though   61           13  \n",
       "...                                                 ...  ...          ...  \n",
       "5567  2nd time tried 2 contact u u 750 pound prize 2...  160           30  \n",
       "5568                        ü b going esplanade fr home   36            8  \n",
       "5569                              pity mood suggestions   57           10  \n",
       "5570  guy bitching acted like interested buying some...  125           26  \n",
       "5571                                     rofl true name   26            6  \n",
       "\n",
       "[5572 rows x 9 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['len']=df['mail'].str.len()\n",
    "\n",
    "df['nombre_mots']=df['mail'].str.split().str.len()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>len</th>\n",
       "      <th>nombre_mots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>2nd time tried 2 contact u u 750 pound prize 2...</td>\n",
       "      <td>160</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>pity mood suggestions</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "      <td>125</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>rofl true name</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  clean  len  nombre_mots\n",
       "0     go jurong point crazy available bugis n great ...  111           20\n",
       "1                               ok lar joking wif u oni   29            6\n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...  155           28\n",
       "3                   u dun say early hor u c already say   49           11\n",
       "4                nah think goes usf lives around though   61           13\n",
       "...                                                 ...  ...          ...\n",
       "5567  2nd time tried 2 contact u u 750 pound prize 2...  160           30\n",
       "5568                        ü b going esplanade fr home   36            8\n",
       "5569                              pity mood suggestions   57           10\n",
       "5570  guy bitching acted like interested buying some...  125           26\n",
       "5571                                     rofl true name   26            6\n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "#X = df.drop(['type'], axis=1)\n",
    "X = df[['clean','len','nombre_mots']]\n",
    "y = df['type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "textColumn = 'clean'\n",
    "numColumn  = ['len','nombre_mots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;data_clean&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;bow&#x27;,\n",
       "                                                  TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                                  decode_error=&#x27;ignore&#x27;,\n",
       "                                                                  ngram_range=(2,\n",
       "                                                                               2),\n",
       "                                                                  strip_accents=&#x27;unicode&#x27;))]),\n",
       "                                 &#x27;clean&#x27;),\n",
       "                                (&#x27;data&#x27;, RobustScaler(),\n",
       "                                 [&#x27;len&#x27;, &#x27;nombre_mots&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-150\" type=\"checkbox\" ><label for=\"sk-estimator-id-150\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;data_clean&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;bow&#x27;,\n",
       "                                                  TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                                  decode_error=&#x27;ignore&#x27;,\n",
       "                                                                  ngram_range=(2,\n",
       "                                                                               2),\n",
       "                                                                  strip_accents=&#x27;unicode&#x27;))]),\n",
       "                                 &#x27;clean&#x27;),\n",
       "                                (&#x27;data&#x27;, RobustScaler(),\n",
       "                                 [&#x27;len&#x27;, &#x27;nombre_mots&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-151\" type=\"checkbox\" ><label for=\"sk-estimator-id-151\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">data_clean</label><div class=\"sk-toggleable__content\"><pre>clean</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-152\" type=\"checkbox\" ><label for=\"sk-estimator-id-152\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, decode_error=&#x27;ignore&#x27;, ngram_range=(2, 2),\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-153\" type=\"checkbox\" ><label for=\"sk-estimator-id-153\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">data</label><div class=\"sk-toggleable__content\"><pre>[&#x27;len&#x27;, &#x27;nombre_mots&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-154\" type=\"checkbox\" ><label for=\"sk-estimator-id-154\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('data_clean',\n",
       "                                 Pipeline(steps=[('bow',\n",
       "                                                  TfidfVectorizer(analyzer='char_wb',\n",
       "                                                                  decode_error='ignore',\n",
       "                                                                  ngram_range=(2,\n",
       "                                                                               2),\n",
       "                                                                  strip_accents='unicode'))]),\n",
       "                                 'clean'),\n",
       "                                ('data', RobustScaler(),\n",
       "                                 ['len', 'nombre_mots'])])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation of textual variables\n",
    "transfo_text_TFid = Pipeline(steps=[\n",
    "    ('bow', TfidfVectorizer(decode_error='ignore', analyzer='char_wb', ngram_range=(2, 2),strip_accents='unicode'))\n",
    "])\n",
    "\n",
    "\n",
    "# Class ColumnTransformer : apply alls steps on the whole dataset\n",
    "preparation = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('data_clean', transfo_text_TFid , textColumn),\n",
    "        ('data',RobustScaler(), numColumn),\n",
    "    ])\n",
    "preparation\n",
    "\n",
    "# svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# estimators = [\n",
    "#      ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "#      ('svr', make_pipeline(StandardScaler(),\n",
    "#                            LinearSVC(dual=\"auto\", random_state=42)))\n",
    "# ]\n",
    "# classifier =StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of model : a ready to use pipeline for ML process\n",
    "\n",
    "classifier =SVC(kernel='linear')\n",
    "# classifier = LogisticRegression(C=1e5)\n",
    "# classifier = ComplementNB()\n",
    "# classifier = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=1019, n_iter=7, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lm = Pipeline([\n",
    "    ('vectorizer', preparation),\n",
    "    ('svd', svd),\n",
    "    ('classifier', classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;data_clean&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;bow&#x27;,\n",
       "                                                                   TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                                                   decode_error=&#x27;ignore&#x27;,\n",
       "                                                                                   ngram_range=(2,\n",
       "                                                                                                2),\n",
       "                                                                                   strip_accents=&#x27;unicode&#x27;))]),\n",
       "                                                  &#x27;clean&#x27;),\n",
       "                                                 (&#x27;data&#x27;, RobustScaler(),\n",
       "                                                  [&#x27;len&#x27;, &#x27;nombre_mots&#x27;])])),\n",
       "                (&#x27;svd&#x27;,\n",
       "                 TruncatedSVD(n_components=1019, n_iter=7, random_state=42)),\n",
       "                (&#x27;classifier&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-155\" type=\"checkbox\" ><label for=\"sk-estimator-id-155\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;data_clean&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;bow&#x27;,\n",
       "                                                                   TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                                                   decode_error=&#x27;ignore&#x27;,\n",
       "                                                                                   ngram_range=(2,\n",
       "                                                                                                2),\n",
       "                                                                                   strip_accents=&#x27;unicode&#x27;))]),\n",
       "                                                  &#x27;clean&#x27;),\n",
       "                                                 (&#x27;data&#x27;, RobustScaler(),\n",
       "                                                  [&#x27;len&#x27;, &#x27;nombre_mots&#x27;])])),\n",
       "                (&#x27;svd&#x27;,\n",
       "                 TruncatedSVD(n_components=1019, n_iter=7, random_state=42)),\n",
       "                (&#x27;classifier&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-156\" type=\"checkbox\" ><label for=\"sk-estimator-id-156\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">vectorizer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;data_clean&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;bow&#x27;,\n",
       "                                                  TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                                  decode_error=&#x27;ignore&#x27;,\n",
       "                                                                  ngram_range=(2,\n",
       "                                                                               2),\n",
       "                                                                  strip_accents=&#x27;unicode&#x27;))]),\n",
       "                                 &#x27;clean&#x27;),\n",
       "                                (&#x27;data&#x27;, RobustScaler(),\n",
       "                                 [&#x27;len&#x27;, &#x27;nombre_mots&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-157\" type=\"checkbox\" ><label for=\"sk-estimator-id-157\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">data_clean</label><div class=\"sk-toggleable__content\"><pre>clean</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-158\" type=\"checkbox\" ><label for=\"sk-estimator-id-158\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, decode_error=&#x27;ignore&#x27;, ngram_range=(2, 2),\n",
       "                strip_accents=&#x27;unicode&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-159\" type=\"checkbox\" ><label for=\"sk-estimator-id-159\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">data</label><div class=\"sk-toggleable__content\"><pre>[&#x27;len&#x27;, &#x27;nombre_mots&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-160\" type=\"checkbox\" ><label for=\"sk-estimator-id-160\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-161\" type=\"checkbox\" ><label for=\"sk-estimator-id-161\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD(n_components=1019, n_iter=7, random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-162\" type=\"checkbox\" ><label for=\"sk-estimator-id-162\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 ColumnTransformer(transformers=[('data_clean',\n",
       "                                                  Pipeline(steps=[('bow',\n",
       "                                                                   TfidfVectorizer(analyzer='char_wb',\n",
       "                                                                                   decode_error='ignore',\n",
       "                                                                                   ngram_range=(2,\n",
       "                                                                                                2),\n",
       "                                                                                   strip_accents='unicode'))]),\n",
       "                                                  'clean'),\n",
       "                                                 ('data', RobustScaler(),\n",
       "                                                  ['len', 'nombre_mots'])])),\n",
       "                ('svd',\n",
       "                 TruncatedSVD(n_components=1019, n_iter=7, random_state=42)),\n",
       "                ('classifier', SVC(kernel='linear'))])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the model\n",
    "model_lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = transfo_text_TFid.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "\n",
    "y_pred = model_lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9856459330143541\n"
     ]
    }
   ],
   "source": [
    "# Performance of the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1448\n",
      "        spam       0.99      0.91      0.94       224\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.99      0.95      0.97      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Afficher le rapport de classification\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(model_lm.decision_function(X_test), bins=50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
